Challenges for the Modern Economist
===================================
author: Lars Vilhuber
date: 2016-05-18
width: 1200
css: custom.css




Challenges for the Modern Economist
===================================

- [Big data](#/data_sources) (but what is it really?)
- [Data availability](#/data_availability) and [accessibility](#/access) (or its disappearing act)
- The conundrum of [confidentiality and privacy](#/privacy)
- [Replicability](#/replicability) (because of all of the above)

[*](#/summary)

Caveats
=============
type: alert
- I don't run my own surveys
- I occasionally create official statistics (bias!)
- I did my Ph.D. in the 1990s

<!-- Challenges discussed here -->
<!-- ======================== -->
<!-- - [challenge from alternate data sources](#/data_sources): [collection](#/collection), [multiplicity](#/multiplicity) -->
<!-- - [increased privacy concerns and stakeholder needs](#/privacy) -->
<!-- - [computational challenges](#/computing) -->
<!-- - [changes in institutional culture](#/culture) -->

Big data
========
id: data_sources
type: section
or rather...

Alternate data sources
======================
type: section

What is "big" data?
==========

What is "big" data?
==========
title: false
incremental: true
Big data is:
- 8 GB?
- 7.5 TB?
- 309.3 million people, measured once?
- 150 million people, measured 80 times?
- 16,721,787,543 tables?
- 100 countries, 5-15 times?
- 19.3 billion records / 50TB?
- 112 weekly data points?

***
Representative big data is:
- I can't run it on my laptop
- 2 years worth of stock trades?
- 10 questions / population/ 1 country?
- 3 variables for 98% of one country's workforce?
- 30+ variables for same?
- 1% samples of 100 countries' censuses?
- 10% of tweets?
- 1 variable for 10% of Twitter users?

What is "big" data? 
==========
incremental: true
- 8 GB? *I can't run it on my laptop, my RA might*
-  7.5TB? *[2 years worth of stock trades](http://dx.doi.org/10.1111/jofi.12185)*
- 309.3 million people, measured once? *10 questions on US decennial census*
- 150 million people, measured 80 times? *[LEHD US linked employer-employee data](https://ideas.repec.org/p/cen/wpaper/14-26.html)*
- 16,721,787,543 tables? *[QWI](http://lehd.ces.census.gov/data) (derived from LEHD)*
- 100 countries, 5-15 times? *[IPUMS](http://www.ipums.org)
- 19.3 billion records **reduced to** 112 weekly data points? = 10% of tweets over 24 months, [UM Economic Indicators from Social Media](http://econprediction.eecs.umich.edu/) (now up to twice that)

This brings up the question: How do we collect data?
=======================
type: section
id: collection


How do we collect data?
================
<!-- incremental: true -->

|       | *Surveys* | *Administrative*  | *Organic Data* |
|-------|-----------|-------------------|----------------|
| **Aim** |Informational  |  Administer programs | ... something else (Twitter?) |
| **Who** |Trained professionals designing, fielding, analyzing surveys|Trained professionals running a bureaucracy, collecting necessary data | Trained professionals optimizing revenue |
| **Core**|Well established science, defining population, frame | Definition of population, frame critical, but ex-post | Population and frame often unclear |
| **Stats** |Primary purpose is to create statistics | Statistics about populations is secondary purpose | Public statistics at best incidental, possibly self-serving |



New challenges
==========
- treating admin/organic as a **noisy data source**,  different from surveys
- designing administrative data collection with **statistics in mind**
- handling **large data flows** in commonly accepted ways
- novel **confidentiality** issues 
<!-- - reconceptualizing **multiciplity** of data sources -->


Data collection in surveys
===============
"**Respondent load** should always be considered when planning a statistical collection and there should be policies and practices in place to **manage relationships** with respondents. The aim should always be to keep reporting load to the **minimum** and to maintain the **high quality** of collections."

[Australian National Statistical Service](http://www.nss.gov.au/nss/home.nsf/NSS/07924BBE95BCC7D2CA25763F00099469?opendocument#3.6)



Data collection in administrative data
=======================
left: 50%
incremental: true

Incentives 
 - Clients cannot get service without filling form
 - Coercion

***

![Monsters](images/roz.jpg)


Data collection discrepancies
=====================
type: section

Data collection discrepancies
===============
**Survey**
- where did you work (precise lat/long) in the past 10 years?
- who did you work for in the past 10 years?

***
**Administrative**
- IRS Form W4, line 8
- CRA-ARC T4, box 54

Data collection discrepancies
===============
Eliminating discrepancies:

![Census3](images/Canadian_Census_2016_consentement3.jpg)

Data collection discrepancies
===============
title: false
type: quote
"Afin de réduire le nombre de questions [...] Statistique Canada utilisera vos données sur le revenu [...]"
[*](#/organic_migration)

Multiplicity of sources
================
type: section
id: multiplicity

Migration sources
================
- [ACS-based county-to-county flows](http://flowsmapper.geo.census.gov/flowsmapper/flowsmapper.html) (5-year horizon) [**survey**]
- [Tax-filing-based county-to-county flows](http://www.forbes.com/special-report/2011/migration.html) (Yearly horizon) [**admin: IRS**]
- [Workplace to residence flows](http://onthemap.ces.census.gov/) (Daily horizon?) [**matched admin**]
- [Workplace based county-to-county (job) flows](http://lehd.ces.census.gov/data/j2j_beta.html) (Quarterly horizon published, others possible) [**admin: states**]

ACS Migration (5-year)
=========================
![ACS Migration](images/Selection_099.png)

IRS Migration (1 year)
===========
![IRS Migration](images/Selection_100.png)


OnTheMap for Burleigh County
==============
![OnTheMap county](images/Selection_101.png)

OnTheMap for North Dakota
==============
![OnTheMap county](images/Selection_103.png)

Job-to-job flows 
==============
![J2J Migration](images/Job-to-Job_LED_20140909-18.png)

Challenges
===========
- Underlying population is the same
- Discrete data products
- Reconciling differences 



Potential organic migration sources
===========================
type: section
id: organic_migration
What about using organic data?

<!-- Potential organic migration sources -->
<!-- =========================== -->
<!-- left: 40% -->
<!-- ![Facebook](images/Selection_096.png) -->
<!-- *** -->
<!-- **Using (changes in) Facebook home location** -->

<!-- Potential organic migration sources -->
<!-- =========================== -->
<!-- left: 60% -->
<!-- ![Twitter](images/Twitter-migration.png) -->
<!-- *** -->

<!-- **Using tweeted information on "new house"** -->


Potential organic migration sources
========================================================
incremental: true
left: 60%

<iframe src="https://player.vimeo.com/video/4587178?autoplay=1&loop=1" width="100%" height="575" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
[Just Landed - 36 Hours](https://vimeo.com/4587178) by [blprnt](https://vimeo.com/user313340)
***

![Twitter](images/Twitter-migration.png)

- Representativeness?
- Reconciling differences is a challenge


Private sector sources
======================
left: 50%

![Social Index](images/Selection_121_early.png)

[U of Michigan Economic Indicators from Social Media](http://econprediction.eecs.umich.edu/)


***

![Google Flu](images/Selection_017.png)

Private sector sources
======================
left: 50%

![BPP](images/bpp.png)
***

![ADP](images/adp.png)

<!-- New statistical sources: Private sector -->
<!-- ======================= -->
<!-- type: alert -->
<!-- type: section -->

<!-- Existing organic statistics -->
<!-- ============================ -->
<!-- ![Google Flu](images/Selection_017.png) -->

<!-- Existing organic statistics -->
<!-- ============================ -->
<!-- ![Social Index](images/SocialMediaUnemployment.png) -->

<!-- [U of Michigan Economic Indicators from Social Media](http://econprediction.eecs.umich.edu/) -->

<!-- Commercial organic statistics -->
<!-- ======================== -->
<!-- ![BPP](images/bpp.png) -->

<!-- Commercial organic statistics -->
<!-- ======================== -->
<!-- ![ADP](images/adp.png) -->

<!-- But notice... -->
<!-- ============= -->
<!-- type: section -->
<!-- incremental: true -->

<!-- ... they all refer back to official statistics! -->


<!-- Benchmarking to NSO: Flu -->
<!-- ============================ -->
<!-- ![Google Flu](images/Selection_105.png) -->

<!-- Benchmarking to NSO: Prices -->
<!-- ============================ -->
<!-- ![Google Flu](images/bpp-hilite.png) -->

<!-- Benchmarking to NSO: Unemployment claims -->
<!-- ============================ -->
<!-- ![Social Index](images/SocialMediaUnemployment-hilite.png) -->

<!-- Benchmarking to NSO: Employment report -->
<!-- ============================ -->
<!-- ![ADP benchmark](images/Selection_109.png) -->

<!-- Challenges from other entities -->
<!-- ====================== -->
<!-- - Timeliness -->
<!-- - Data collection by non-NSO -->

J'en veux!
==========
title: false
type: quote
J'en veux!

Vous pouvez
==========
title: false
type: quote
Vous pouvez.

Example: Timeliness of Census 2016
==========
A Metadata Question
![consent](images/Canadian_Census_2016_consentement1.png)

Availability of Consent?
================
![Census 2016 release](images/Selection_236_fr.png)

8 février 2017

An estimate using GCS
===========
incremental: true
As of 2016-05-17, 11:18

![GCS-20160517](images/GCS-consent-20160517-1118.png)

An estimate using GCS
===========
Google Consumer Survey
- Question: On the Canadian Census 2016, did you consent to making your information available in 2108 (in 92 years)?
- Goal: 500 responses
- Fielded: 2016-05-16
- As of: 2016-05-17 11:18, 229 responses
[live](https://www.google.com/insights/consumersurveys/view?survey=qht3vffpx6peusl5jopzboksqm)


An Aside...
==========
Live download from https://www.googleapis.com/consumersurveys/v2/surveys/qht3vffpx6peusl5jopzboksqm/results
```{r error,eval=FALSE}
{
 "error": {
  "errors": [
   {
    "domain": "global",
    "reason": "required",
    "message": "Login Required",
    "locationType": "header",
    "location": "Authorization"
   }
  ],
  "code": 401,
  "message": "Login Required"
 }
}
```

The Power of...
================
- immediate estimate
- timeliness
- "enhancement" possible
- Cost: $50...

Other  tools
===========
Google
- Google Trends
- Google Correlate


Challenges to Data Availability
=============================
type: section
id: availability

Data Availability
================
Two challenges:
 - computation and storage 
 - [access](#/access)
 
Size and Computation
====================
type: quote
"● A billion hours ago, modern homo sapiens emerged.
● A billion minutes ago, Christianity began.
● A billion seconds ago, the IBM PC was released.
● A billion Google searches ago … was this morning."

 [Hal Varian](http://people.ischool.berkeley.edu/~hal/Papers/2013/BeyondBigDataPaperFINAL.pdf)

Example: Predicting House Sales with Search Data
===================================
![House sales](images/Selection_233.png)

[Wu and Brynjolfsson](http://dx.doi.org/10.2139/ssrn.2022293)

Example: Michigan Twitter feed
======================
<!-- ![Social Index](images/SocialMediaUnemployment.png) -->
![Social Index](images/Selection_121_early.png)

[U of Michigan Economic Indicators from Social Media](http://econprediction.eecs.umich.edu/)

Benefits of using Twitter
=========================
[D Antenucci et al (2014)](http://www-personal.umich.edu/~shapiro/papers/LaborFlowsSocialMedia.pdf)
- compared to  weekly frequency of the official (US) UI claims (high
frequency and without sampling error)
- high-frequency social media index tracks events that affect the job market in real time
- index has greater signal to noise ratio than the official initial claims series 

Cost of using Twitter or other sources
====================
- cost of storing 60-70+ TB of data
- scraping
- maintaining software


How to Validate?
================
type: alert

See [later](#/replication)


Example: Quarterly Workforce Indicators
======================================
Based on quarterly wage reports from 50 states and DC:
- research file (LEHD Snapshot through 2012Q1) has information on 
  - 1,579,393,000 jobs for 
  - 262,106,000 people in 
  - 21,793,000 firms
- statistics re-computed quarterly (full-information model)


Challenge: Consensus Sampling of Big Data
==========================================
type: alert

Example: Michigan Twitter feed
======================
<!-- ![Social Index](images/SocialMediaUnemployment.png) -->
![Social Index](images/Selection_121_early.png)

Critical Sampling by the Author Team
=================
Clearly explained in [the article](http://www-personal.umich.edu/~shapiro/papers/LaborFlowsSocialMedia.pdf):
- 10 percent sample of all Tweets (first 28 months = 43.8TB)
- analyze *k-grams* ($k\leq4$), aggregated first to days and then weeks
- narrow the feature space further by using domain knowledge
Question:
- how can we second-guess?


In physics...
==================
![CERN](images/cern-lhc-firsthalfofcmsinnertrackerbarrel.jpg)

Data processing in physics
==========================
incremental: true
- Arecibo Radiotelescope (since 1963)
- Large Hadron Collider (since 2008)

Data processing in physics
========================
incremental: true
left: 60%
id: physics_video
<iframe width="640" height="360" frameborder="0" src="https://cds.cern.ch/video/CERN-MOVIE-2013-041-001?autoplay=1" ></iframe>
[jump](#/end_physics)
***
- raw data: 600 million collisions every second
- theory says 1 in a million of interest
- HARDWARE pre-selects (0.01%) [[CERN animation](http://home.web.cern.ch/about/updates/2013/04/animation-shows-lhc-data-processing)]
- SOFTWARE selects (1%) using 15,000  processors 
- STORE 25 Petabytes/year to 11 centers
- ANALYZE in 170 centers

Raw data
=========
600 million collisions every second = 1 PB/s
![600 million](images/Selection_229.png)

Theory
======
1 in a *million* of interest
![1 in million](images/Selection_230.png)

Consensus in Domain
==============
HARDWARE pre-selects (0.01%) - throws away 99.99% of data! Forever!
![Hardware](images/Selection_231.png)

Possibility to reassess
======================
SOFTWARE selects (1%) using 15,000  processors 
![Software](images/Selection_232.png)

[stop](#/physics_video)


For social scientists
========================================
id: end_physics
Computing gap
- Census Bureau vs. XSEDE
- Statistics Canada vs. Compute Canada

Challenges in
- moving data to compute resource, or
- compute resource to data

For social scientists
========================================
Administrative data and organic data increase the challenge
- Google and Twitter provide
  - storage resources 
  - implement data reduction
  - ... without scientific consensus



















Challenges: Access
==================
type: section
id: access


Data Collection Procedures
==================================
How are administrative data collected and stored?
 - often complex and ... organic
 - sometimes obfuscated
 - very heterogeneous

Example: Quarterly Workforce Indicators 
======================================
![QWI dates](images/qwipu_plot-1024x1024.png)

Historical availability already compromised
 - cost
 - legal 

Data Collection Procedures
==================================
How are organic data collected and stored?
 - incidental
 - selectively?

Example: Michigan Twitter feed
======================
![Social Index](images/SocialMediaUnemployment-hilite.png)

Access to the raw data of the Ringtail system?

Example: Twitter again (sorry)
===========================
type: alert
![Twitter cuts off access](images/Selection_227.png)

[CNBC, 2016-05-09](http://www.cnbc.com/2016/05/09/twitter-against-government-access-to-data-mining-service-report.html)

Example: Quarterly Workforce Indicators Again
======================================
How to validate: 
- Request access to the **14** (out of **50**) states who have given access to non-government researchers 

![Snapshot as of 2012Q1](images/Selection_228.png)


Administrative data silos
======================
incremental: true
Many of the examples above are "siloed" because of computational constraints.

Administrative data is often "siloed" for a combination of (perceived and real) confidentiality constraints and legal barriers.

Example: Quarterly Workforce Indicators (Again)
======================================
LEHD succeeded in brining together 51 (+) state administrations, sharing their data to a trusted party.

Success: QWI

Less so: Researcher access (14 out of 51)

Example: European Data
====================
incremental: true
Mostly in confidential silos

Broad consensus on legal framework

![Fight](images/fight-cartoons1.jpeg)
Still some issues

Example: European Data
====================
28 countries
- ![Eurostat](images/20150318150730!Eurostat_logo_RGB_60.jpg)
- very little common data 
- no common access to administrative data

Example: Canadian Data
====================
incremental: true
10 provinces + 3 territories + 1 federal government
- 14 silos
- ![Fight](images/fight-cartoons1.jpeg)







Challenges: Privacy
================
type: section
id: privacy

Challenges: Protection gap
================
incremental: true
- More detailed data implies more data on specific individuals and firms
- Are protection methods sufficient?
 - Statistics offices are concerned
 - Administrations are concerned
 - Private providers are taking action, because they are concerned.

One Solution:
============
incremental: true
type: quote
left: 50%
Lock up the researcher

***
![Scottish RDC](images/SafePODS.png)

<!-- ![Scottish RDC](images/SafePODS2.jpg) -->

Access methods
=======================
incremental: true
- apply methods, produce more public-use statistics (move the data to the researcher)
- fail to apply methods, provide controlled direct access to data (move the researcher to the data; contracts/RDCs/etc.)

Privacy and Confidentiality
=======================
One view
- Privacy is not asking
- Confidentiality is not revealing


Example: Census 2016
==================
incremental: true
![Consent1](images/Canadian_Census_2016_consentement1.png)

![Consent3](images/Canadian_Census_2016_consentement3.jpg)

Example: Census 2016
==================

Statistics Canada
- asks the respondents about the data on the Census form (compulsory response!) = confidentiality
- makes the decision to use the respondents' tax data (also compulsory response!) = privacy (or not) 

An Indication of the Desire for Privacy
============================
![decline](images/GCS-consent-20160517-1118.png)


What level of protection?
======================
- older methods break down as published data become denser
- newer methods are still being developed
  - synthetic data
  - noise infusion
- more robust methods
  - differential privacy

How much protection?
===================
- tradeoff utility - protection
- how much protection do data providers require (people, firms, etc.)
- how much utility do stakeholders request (people, firms, government, etc.)
- what technology is available to implement?

How much protection?
=====================
![PPF utility-privacy](images/plannersprob.png)
<small>[Abowd and Schmutte, Revisiting   the	  Economics	  of	Privacy:	  Population	  Statistics	  and	Privacy	
as	  Public	  Goods](http://digitalcommons.ilr.cornell.edu/ldi/22/)</small>



<!-- Challenge: Cultural change -->
<!-- ======================== -->
<!-- type: section -->

<!-- Change in the culture -->
<!-- =================== -->
<!-- incremental: true -->
<!-- - computing approaches require a change in procedures -->
<!-- - openness to new research methods (not in statistics!) and new skill sets (not in statistics!) -->
<!-- - academic-agency collaborations are an important part -->


<!-- Change in culture -->
<!-- ================= -->
<!-- "... the current Census Bureau survey and census methods are -->
<!-- **unsustainable**. Changes must occur in the acquisition of data and -->
<!-- construction of statistical information for the Census Bureau to succeed." -->

<!-- _Robert Groves, Director, Census Bureau, September 8, 2011_ -->

<!-- Change in culture -->
<!-- ================= -->
<!-- "Modern computational tools play the same role now that survey design and -->
<!-- implementation did in the 1960s." -->

<!-- _John Abowd and Steve Fienberg, CNSTAT, May 8, 2015_ -->

<!-- Change in culture -->
<!-- ================ -->
<!-- "We would like to suggest [...] -->
<!-- implementing a variety of new models for facilitating the -->
<!-- **movements of researchers** between academia and the Federal -->
<!-- Statistical System" -->

<!-- _Report of the NSF reverse site visit of the NCRN, April 2015_ -->

<!-- Summary: Challenges for NSO -->
<!-- =========================== -->
<!-- id: summary -->
<!-- type: section -->

<!-- Summary: Challenges for NSO -->
<!-- =========================== -->
<!-- incremental: true -->
<!-- - [challenge from alternate data sources](#/data_sources):  -->
<!--   - open up to alternate data sources -->
<!--   - new science on how to address distributed, independently generated data sources -->
<!-- - [increased privacy concerns and stakeholder needs](#/privacy) -->
<!--   - investigate new methods to address privacy issues (access, disclosure avoidance techniques) -->
<!--   - better toolkit to identify the right balance between stakeholder utility and data provider privacy -->
<!-- - [computational challenges](#/computing) -->
<!--   - shift in computational infrastructure (both production and research; also access) -->
<!-- - [changes in institutional culture](#/culture) -->
<!--   - increased focus on interactions with academia -->
<!--   - expansion of staff skill diversity, in addition to traditional skill sets -->

Challenges: Replication
======================
type: section
id: replication


Where are we?
===============
incremental: true
- Data are more complex
- Data are more difficult to share
- Data are more siloed 



But we like the results!
======================
type: quote
title: false
But we like the results!



But we like the results!
==================
type: alert
left: 50%
![Chetty](images/ChettySlide2.png)
<small>[Chetty, Time Trends in the Use of Administrative Data for Empirical Research
NBER Summer Institute, July 2012](http://www.rajchetty.com/chettyfiles/admin_data_trends.pdf)</small>

***
![citations](images/citationcnt-1.png)
<small>Kingi, Stanchi, Vilhuber (unpublished)</small>


Replicating the Results
======================
![Social Index](images/SocialMediaUnemployment-hilite.png)

Difficult to replicate

Kingi, Stanchi, Vilhuber
=======================
![access](images/Selection_192.png)

Significant number of papers not reproducible because of access difficulties

Kingi, Stanchi, Vilhuber
====================
![type of access](images/ksv-table4.png)


Should We Just Trust These Guys?
===============
left: 25%
***
![Car salesman](images/usedcarsalesman.jpg)


Conclusion
===========
id: conclusion
incremental: true
type: section

Big data
========
Or maybe:
**Pervasive data**

Data availability and accessibility
==============
- the era of public-use data is declining
  - because other data are more interesting, richer
- data sources multiply...
  - ... but also hide in new silos

Confidentiality and privacy
===================
- Confidentiality by obscurity is dead
- the era of public-use data is declining
  - because confidentiality is too easy to compromise
- data sources multiply...
  - ... making the risk of confidentiality breach more obvious
  - ... enforcing the creation of silos

Confidentiality and privacy
==========================
Challenge is to
- fuse the silos (f.i. provincial data available in national network)
- develop new methods that are robust to confidentiality protection methods

Big data
======
- new "big data" methods will become part of the canon of applied economics
- will include methods absorbed from computer science, biology, physics
- will need to iterate towards a consensus what data to keep (à la physics)

Replicability
=============
- all of the above constitute a challenge to the scientific integrity of our findings
- for old-style data, greater replicability will be required
- for new-style data, new methods to allow for replication need to be developed
  - building big data infrastructure may require building an access mechanism as well (synthetic data, validation server)
  - social science archives need to make a magnitude leap in archiving capability
- funding






Thank you
===========
type: section
id: end
